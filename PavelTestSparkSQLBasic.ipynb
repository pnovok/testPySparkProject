{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a347d47-cbdb-46b9-a884-e47d1c542de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import Row, StructField, StructType, StringType, IntegerType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c785f10c-f576-4f15-bc22-9223625a1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Spark Session\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"SampleSparkSQLApp\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28affce1-2e61-4866-9fec-d7e4e2ceacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a sample dataframe with 10 rows, numbers from 0 to 10\n",
    "myRange = spark.range(10).toDF(\"number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa1270df-27d1-451d-bf7b-97da9ea381e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- number: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Pring the schema\n",
    "myRange.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a15635b6-c7d7-4820-9b4d-2141d7ce296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "|     2|\n",
      "|     3|\n",
      "|     4|\n",
      "|     5|\n",
      "|     6|\n",
      "|     7|\n",
      "|     8|\n",
      "|     9|\n",
      "+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Show the contents of the DF\n",
    "myRange.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3898fdfe-70eb-4791-9527-282f32884e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Reading a File to a DF\n",
    "flightData2015 = spark\\\n",
    "  .read\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .csv(\"/home/cdsw/resources/flight-data/csv/2015-summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03336816-669d-4a49-a5a0-0b56a84a5c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print Schema\n",
    "flightData2015.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86e4ab64-7dde-4df1-833b-9f836eadff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Register a Temp View and convert a DF into a table\n",
    "flightData2015.createOrReplaceTempView(\"flight_data_2015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04bf5b31-55cc-441d-8c5c-f5d8d9d98b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the first 3 rows\n",
    "flightData2015.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c3ea631-51bd-4284-ab3a-c6954aec7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prep SQL in a SQL Way\n",
    "sqlWay = spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, count(1)\n",
    "FROM flight_data_2015\n",
    "GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "938e7b4d-5794-4a1c-bd51-1208bd50dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prep SQL in a DF way\n",
    "dataFrameWay = flightData2015\\\n",
    "  .groupBy(\"DEST_COUNTRY_NAME\")\\\n",
    "  .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4101a164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[DEST_COUNTRY_NAME#70], functions=[count(1)])\n",
      "   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#70, 200), ENSURE_REQUIREMENTS, [plan_id=185]\n",
      "      +- HashAggregate(keys=[DEST_COUNTRY_NAME#70], functions=[partial_count(1)])\n",
      "         +- FileScan csv [DEST_COUNTRY_NAME#70] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/cdsw/resources/flight-data/csv/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run Explain on SQL\n",
    "sqlWay.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c621f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[DEST_COUNTRY_NAME#70], functions=[count(1)])\n",
      "   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#70, 200), ENSURE_REQUIREMENTS, [plan_id=198]\n",
      "      +- HashAggregate(keys=[DEST_COUNTRY_NAME#70], functions=[partial_count(1)])\n",
      "         +- FileScan csv [DEST_COUNTRY_NAME#70] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/cdsw/resources/flight-data/csv/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run Explain on DF\n",
    "dataFrameWay.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6f2df1c-d83b-4eed-89a5-9f069110c704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|   DEST_COUNTRY_NAME|count(1)|\n",
      "+--------------------+--------+\n",
      "|            Anguilla|       1|\n",
      "|              Russia|       1|\n",
      "|            Paraguay|       1|\n",
      "|             Senegal|       1|\n",
      "|              Sweden|       1|\n",
      "|            Kiribati|       1|\n",
      "|              Guyana|       1|\n",
      "|         Philippines|       1|\n",
      "|            Djibouti|       1|\n",
      "|            Malaysia|       1|\n",
      "|           Singapore|       1|\n",
      "|                Fiji|       1|\n",
      "|              Turkey|       1|\n",
      "|                Iraq|       1|\n",
      "|             Germany|       1|\n",
      "|              Jordan|       1|\n",
      "|               Palau|       1|\n",
      "|Turks and Caicos ...|       1|\n",
      "|              France|       1|\n",
      "|              Greece|       1|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run SQL\n",
    "sqlWay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "198c718c-0441-4736-a565-4e57ae239aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14ff4412-344c-47ae-811b-5dbfd38aa6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(count)=370002)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightData2015.select(max(\"count\")).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "179794e6-7dac-48aa-9c70-4f3a27575749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find top 5 destination countries with a SQL way\n",
    "maxSql = spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, sum(count) as destination_total\n",
    "FROM flight_data_2015\n",
    "GROUP BY DEST_COUNTRY_NAME\n",
    "ORDER BY sum(count) DESC\n",
    "LIMIT 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2192ad7-1a5e-4ae4-bd54-666f1c784df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|destination_total|\n",
      "+-----------------+-----------------+\n",
      "|    United States|           411352|\n",
      "|           Canada|             8399|\n",
      "|           Mexico|             7140|\n",
      "|   United Kingdom|             2025|\n",
      "|            Japan|             1548|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxSql.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adcb5da9-e495-4cd7-9050-54a200ff1380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|destination_total|\n",
      "+-----------------+-----------------+\n",
      "|    United States|           411352|\n",
      "|           Canada|             8399|\n",
      "|           Mexico|             7140|\n",
      "|   United Kingdom|             2025|\n",
      "|            Japan|             1548|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Find top 5 destinations countries with a DF way\n",
    "from pyspark.sql.functions import desc\n",
    "flightData2015\\\n",
    "  .groupBy(\"DEST_COUNTRY_NAME\")\\\n",
    "  .sum(\"count\")\\\n",
    "  .withColumnRenamed(\"sum(count)\", \"destination_total\")\\\n",
    "  .sort(desc(\"destination_total\"))\\\n",
    "  .limit(5)\\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d4f9e4d-4d43-4286-8069-73df76dae25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- TakeOrderedAndProject(limit=5, orderBy=[destination_total#76L DESC NULLS LAST], output=[DEST_COUNTRY_NAME#38,destination_total#76L])\n",
      "   +- HashAggregate(keys=[DEST_COUNTRY_NAME#38], functions=[sum(count#40)])\n",
      "      +- Exchange hashpartitioning(DEST_COUNTRY_NAME#38, 200), ENSURE_REQUIREMENTS, [plan_id=115]\n",
      "         +- HashAggregate(keys=[DEST_COUNTRY_NAME#38], functions=[partial_sum(count#40)])\n",
      "            +- FileScan csv [DEST_COUNTRY_NAME#38,count#40] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/cdsw/resources/flight-data/csv/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,count:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015\\\n",
    "  .groupBy(\"DEST_COUNTRY_NAME\")\\\n",
    "  .sum(\"count\")\\\n",
    "  .withColumnRenamed(\"sum(count)\", \"destination_total\")\\\n",
    "  .sort(desc(\"destination_total\"))\\\n",
    "  .limit(5)\\\n",
    "  .explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4060b62b-62be-4236-b0d6-42dd7cc6f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
