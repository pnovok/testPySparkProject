{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e550dd-63f6-4eda-9dc7-6fd9d621fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import Row, StructField, StructType, StringType, IntegerType, DateType, DecimalType\n",
    "from pyspark.sql.functions import desc\n",
    "import pandas as pd\n",
    "#import pyspark.sql.functions as f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2956d454-7798-4786-a7a2-52abc5a30bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"PythonSQL\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "991b663e-bebc-4e9e-b19a-25288defbbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "| John| 19|\n",
      "|Smith| 23|\n",
      "|Sarah| 18|\n",
      "+-----+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# A list of Rows. Infer schema from the first row, create a DataFrame and print the schema\n",
    "rows = [Row(name=\"John\", age=19), Row(name=\"Smith\", age=23), Row(name=\"Sarah\", age=18)]\n",
    "some_df = spark.createDataFrame(rows)\n",
    "some_df.printSchema()\n",
    "some_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50504668-6537-4803-96e8-b7c9b0d25dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of tuples\n",
    "tuples = [(\"John\", 19), (\"Smith\", 23), (\"Sarah\", 18)]\n",
    "\n",
    "# Schema with two fields - person_name and person_age\n",
    "schema = StructType([StructField(\"person_name\", StringType(), False),\n",
    "                    StructField(\"person_age\", IntegerType(), False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b05bbeaa-a6df-40b9-bd5f-76e27f6dd6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- person_name: string (nullable = false)\n",
      " |-- person_age: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame by applying the schema to the RDD and print the schema\n",
    "another_df = spark.createDataFrame(tuples, schema)\n",
    "another_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b46a0478-79be-45a4-804f-67905b27f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/cdsw/resources/people.json\"\n",
    "\n",
    "# Create a DataFrame from the file(s) pointed to by path\n",
    "people = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3b2834f-c737-46d7-a198-afde9283d582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The inferred schema can be visualized using the printSchema() method.\n",
    "people.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bc44ff9-3e27-4dcf-bc55-76f1d4b49180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a temporary view using the DataFrame.\n",
    "people.createOrReplaceTempView(\"people\")\n",
    "\n",
    "# SQL statements can be run by using the sql methods provided by `spark`\n",
    "teenagers = spark.sql(\"SELECT name FROM people WHERE age >= 13 AND age <= 19\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b5aff64-d786-4f72-83fb-60e7e2113e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Justin\n"
     ]
    }
   ],
   "source": [
    "for each in teenagers.collect():\n",
    "    print(each[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19e49def-d767-4931-9ed6-5ed069d9b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering in a DF Way\n",
    "teenagers = people.filter(\"age >= 13 and age <= 19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72f39f3c-9097-4836-a949-6b08820a552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  name|age|\n",
      "+------+---+\n",
      "|Justin| 19|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teenagers.select(\"name\",\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1da4d10d-cf09-4fcd-b9d1-f845ca23c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define schema for the emp.csv file\n",
    "schema_emp = StructType([\n",
    "    StructField(\"emp\", IntegerType(), True),\n",
    "    StructField(\"mgr\", IntegerType(), True),\n",
    "    StructField(\"dept\", IntegerType(), True),\n",
    "    StructField(\"job\",IntegerType(), True),\n",
    "    StructField(\"l_name\",StringType(), True),\n",
    "    StructField(\"f_name\",StringType(), True),\n",
    "    StructField(\"hire\",DateType(), True),\n",
    "    StructField(\"birth\", DateType(), True),\n",
    "    StructField(\"salary\",DecimalType(), True)             \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d42eabf7-55fb-489e-9b88-383b321a66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DF for emp\n",
    "empDF = spark.read.option(\"delimiter\", \",\").option(\"header\", False).csv(\"/home/cdsw/resources/testdata/emp.csv\",schema=schema_emp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "145f6ef3-6608-40d7-9c31-09638ac3ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a schema for dept.csv file\n",
    "schema_dept = StructType([\n",
    "    StructField(\"dept\", IntegerType(), True),\n",
    "    StructField(\"deptName\", StringType(), True),\n",
    "    StructField(\"budget\", DecimalType(), True),\n",
    "    StructField(\"mgr\",IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e548f6ef-93ed-4a69-8b49-126abbcb3738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DF for dept file\n",
    "deptDF = spark.read.option(\"delimiter\", \",\").option(\"header\", False).csv(\"/home/cdsw/resources/testdata/dept.csv\",schema=schema_dept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b649d569-b41c-4dc1-8cea-a393e5d3ee07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+------+--------+------+----------+----------+------+\n",
      "| emp| mgr|dept|   job|  l_name|f_name|      hire|     birth|salary|\n",
      "+----+----+----+------+--------+------+----------+----------+------+\n",
      "|1017| 801| 501|511100|  Runyon| Irene|1978-05-01|1951-11-10| 66000|\n",
      "|1018|1017| 501|512101|Ratzlaff| Larry|1978-07-15|1954-05-31| 54000|\n",
      "|1015|1017| 501|512101|  Wilson|Edward|1978-03-01|1957-03-04| 53625|\n",
      "|1023|1017| 501|512101|  Rabbit| Peter|1979-03-01|1962-10-29| 26500|\n",
      "+----+----+----+------+--------+------+----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filer() and orderBy() - List all employess from dept 501 ordered by salary in descending order\n",
    "empDF.filter(\"dept = 501\").orderBy(\"salary\",ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2db5d522-5d60-4b0a-9a20-f7e7a29e2958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+------+--------+------+----------+----------+------+----+---------------+------+----+\n",
      "| emp| mgr|dept|   job|  l_name|f_name|      hire|     birth|salary|dept|       deptName|budget| mgr|\n",
      "+----+----+----+------+--------+------+----------+----------+------+----+---------------+------+----+\n",
      "|1018|1017| 501|512101|Ratzlaff| Larry|1978-07-15|1954-05-31| 54000| 501|marketing sales|308000|1017|\n",
      "|1017| 801| 501|511100|  Runyon| Irene|1978-05-01|1951-11-10| 66000| 501|marketing sales|308000|1017|\n",
      "|1015|1017| 501|512101|  Wilson|Edward|1978-03-01|1957-03-04| 53625| 501|marketing sales|308000|1017|\n",
      "|1023|1017| 501|512101|  Rabbit| Peter|1979-03-01|1962-10-29| 26500| 501|marketing sales|308000|1017|\n",
      "+----+----+----+------+--------+------+----------+----------+------+----+---------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now perform a join using DF API\n",
    "empDF.filter(\"dept = 501\").join(deptDF,empDF.dept==deptDF.dept).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0d68b86-703e-4843-9c4e-30c14c86fcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's do the join between 2 DF in a SQL manner. First create 2 temp views\n",
    "empDF.createOrReplaceTempView(\"employee\")\n",
    "deptDF.createOrReplaceTempView(\"department\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "730658c3-77d5-40a7-8559-8867cf12772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+------+--------+------+----------+----------+------+----+---------------+------+----+\n",
      "| emp| mgr|dept|   job|  l_name|f_name|      hire|     birth|salary|dept|       deptName|budget| mgr|\n",
      "+----+----+----+------+--------+------+----------+----------+------+----+---------------+------+----+\n",
      "|1018|1017| 501|512101|Ratzlaff| Larry|1978-07-15|1954-05-31| 54000| 501|marketing sales|308000|1017|\n",
      "|1017| 801| 501|511100|  Runyon| Irene|1978-05-01|1951-11-10| 66000| 501|marketing sales|308000|1017|\n",
      "|1015|1017| 501|512101|  Wilson|Edward|1978-03-01|1957-03-04| 53625| 501|marketing sales|308000|1017|\n",
      "|1023|1017| 501|512101|  Rabbit| Peter|1979-03-01|1962-10-29| 26500| 501|marketing sales|308000|1017|\n",
      "+----+----+----+------+--------+------+----------+----------+------+----+---------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now Run the join statement.\n",
    "joinData = spark.sql(\"select * from employee inner join department on employee.dept=department.dept where employee.dept=501\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecce870e-3bed-4fbb-a81b-24cbafc64116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------+----+\n",
      "|dept|            deptName|budget| mgr|\n",
      "+----+--------------------+------+----+\n",
      "| 301|research and deve...|465600|1019|\n",
      "| 501|     marketing sales|308000|1017|\n",
      "+----+--------------------+------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Example for show(), first(), take(), limit()\n",
    "#show() gives a formated output and prints results\n",
    "deptDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "990a259f-d457-4071-8940-692fdab629df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(dept=301, deptName='research and development', budget=Decimal('465600'), mgr=1019)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first() also returns a list of rows\n",
    "deptDF.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34977660-090d-41bc-8784-1eef23bed8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dept=301, deptName='research and development', budget=Decimal('465600'), mgr=1019),\n",
       " Row(dept=501, deptName='marketing sales', budget=Decimal('308000'), mgr=1017)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take() returns a list of rows and can be used to create a new DF\n",
    "deptDF.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82f21279-47bf-4534-9789-5504348ef5ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|dept|\n",
      "+----+\n",
      "| 301|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Distinct with Filter\n",
    "empDF.select(\"dept\").filter(\"dept = 301\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1c1966e-087d-4877-84bd-afda4770bb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|dept|count|\n",
      "+----+-----+\n",
      "| 501|    4|\n",
      "| 402|    2|\n",
      "| 301|    3|\n",
      "| 100|    1|\n",
      "| 403|    6|\n",
      "| 201|    2|\n",
      "| 302|    1|\n",
      "| 401|    7|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Group By with count() and sum()\n",
    "#Show the total number of empolyees per department\n",
    "empDF.groupBy(empDF.dept).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edcd6f67-dfb0-4da1-80a5-a66e58434965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|dept|sum(salary)|\n",
      "+----+-----------+\n",
      "| 501|     200125|\n",
      "| 402|      77000|\n",
      "| 301|     116400|\n",
      "| 100|     100000|\n",
      "| 403|     233000|\n",
      "| 201|      73450|\n",
      "| 302|      56500|\n",
      "| 401|     245575|\n",
      "+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Show the summary of salaries by department\n",
    "empDF.groupBy(\"dept\").sum(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcd0956b-fa48-483c-9081-24c4d6dffdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|dept|  avgSalary|\n",
      "+----+-----------+\n",
      "| 100|100000.0000|\n",
      "| 302| 56500.0000|\n",
      "| 501| 50031.2500|\n",
      "| 403| 38833.3333|\n",
      "| 301| 38800.0000|\n",
      "| 402| 38500.0000|\n",
      "| 201| 36725.0000|\n",
      "| 401| 35082.1429|\n",
      "+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Show average salary by department order by in desc order\n",
    "empDF\\\n",
    ".select(\"dept\", \"salary\")\\\n",
    ".groupBy(\"dept\")\\\n",
    ".avg(\"salary\")\\\n",
    ".withColumnRenamed(\"avg(salary)\", \"avgSalary\")\\\n",
    ".sort(desc(\"avgSalary\"))\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13fcf701-6136-4460-8be7-fd8d25b02510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write DF to the output csv file\n",
    "#empDF.write.csv(\"/tmp/pavel_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eee31eac-7d29-454e-887a-64ec6ba8d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dc370e-96b2-4f70-9fff-1bb42acdff69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
